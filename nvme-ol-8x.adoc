---
sidebar: sidebar 
permalink: nvme-ol-8x.html 
keywords: nvme, oracle linux, 8.x, host configuration 
summary: 适用于 Oracle Linux 8.x 和ONTAP的 NVMe-oF 主机配置 
---
= 配置 Oracle Linux 8.x 和 NVMe-oF 以用于ONTAP存储
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Oracle Linux 主机支持基于光纤通道的 NVMe (NVMe/FC) 和基于 TCP 的 NVMe (NVMe/TCP) 协议，并支持非对称命名空间访问 (ANA)。ANA 提供与 iSCSI 和 FCP 环境中的非对称逻辑单元访问 (ALUA) 等效的多路径功能。

了解如何为 Oracle Linux 8.x 配置 NVMe over Fabrics (NVMe-oF) 主机。如需更多支持和功能信息，请参阅 link:nvme-ol-supported-features.html["Oracle Linux ONTAP支持和功能"]。

NVMe-oF 与 Oracle Linux 8.x 存在以下已知限制：

* 不支持使用 NVMe-oF 协议进行 SAN 启动。
* NetApp sanlun 主机实用程序不支持 Oracle Linux 8.x 主机上的 NVMe-oF。相反，您可以依赖本机中包含的NetApp插件 `nvme-cli`适用于所有 NVMe-oF 传输的包。
* 对于 Oracle Linux 8.2 及更早版本，nvme-cli 软件包中不提供原生 NVMe/FC 自动连接脚本。使用 HBA 供应商提供的外部自动连接脚本。
* 对于 Oracle Linux 8.2 及更早版本，默认情况下不会为 NVMe 多路径启用轮询负载均衡。要启用此功能，请转到以下步骤。<<udev-rule,编写 udev 规则>> 。




== 步骤 1：安装 Oracle Linux 和 NVMe 软件并验证您的配置

使用以下步骤验证支持的最低 Oracle Linux 8.x 软件版本。

.步骤
. 在服务器上安装Oracle Linux 8.x。安装完成后，请确认您运行的是指定的 Oracle Linux 8.x 内核。
+
[source, cli]
----
uname -r
----
+
Oracle Linux 内核版本示例：

+
[listing]
----
5.15.0-206.153.7.1.el8uek.x86_64
----
. 安装 `NVMe-CLI` 软件包：
+
[source, cli]
----
rpm -qa|grep nvme-cli
----
+
下面的例子展示了 `nvme-cli`软件包版本：

+
[listing]
----
nvme-cli-1.16-9.el8.x86_64
----
. [[udev-rule]] 对于 Oracle Linux 8.2 及更早版本，请添加以下字符串作为单独的 udev 规则。 `/lib/udev/rules.d/71-nvme-iopolicy-netapp-ONTAP.rules` 。这样就实现了 NVMe 多路径的轮询负载均衡。
+
[source, cli]
----
cat /lib/udev/rules.d/71-nvme-iopolicy-netapp-ONTAP.rules
Enable round-robin for NetApp ONTAP
ACTION=="add", SUBSYSTEMS=="nvme-subsystem", ATTRS{model}=="NetApp ONTAP Controller", ATTR{iopolicy}="round-robin"
----
. 在 Oracle Linux 8.x 主机上，检查 `hostnqn`字符串 `/etc/nvme/hostnqn`：
+
[source, cli]
----
cat /etc/nvme/hostnqn
----
+
下面的例子展示了 `hostnqn`版本：

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
----
. 在ONTAP系统中，验证以下信息： `hostnqn`字符串匹配 `hostnqn`ONTAP存储系统中相应子系统的字符串：
+
[source, cli]
----
vserver nvme subsystem host show -vserver vs_coexistence_LPE36002
----
+
.显示示例
[%collapsible]
====
[listing, subs="+quotes"]
----
Vserver Subsystem Priority  Host NQN
------- --------- --------  ------------------------------------------------
vs_coexistence_LPE36002
        nvme
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme1
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme2
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme3
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
4 entries were displayed.
----
====
+

NOTE: 如果 `hostnqn`字符串不匹配、请使用 `vserver modify`命令更新 `hostnqn`相应ONTAP阵列子系统上的字符串、使其与主机上的字符串 `/etc/nvme/hostnqn`匹配 `hostnqn`。

. 此外，为了在同一主机上同时运行 NVMe 和 SCSI 流量， NetApp建议对ONTAP命名空间使用内核 NVMe 多路径。 `dm-multipath`分别对应ONTAP LUN。这样应该可以将ONTAP命名空间排除在外。 `dm-multipath`并阻止 `dm-multipath`拒绝声明ONTAP命名空间设备。
+
.. 添加 `enable_foreign`设置 `/etc/multipath.conf`文件。
+
[source, cli]
----
cat /etc/multipath.conf
defaults {
  enable_foreign     NONE
}
----
.. 重新启动 `multipathd`守护进程应用新设置。
+
[source, cli]
----
systemctl restart multipathd
----






== 步骤 2：配置 NVMe/FC 和 NVMe/TCP

使用 Broadcom/Emulex 或 Marvell/QLogic 适配器配置 NVMe/FC，或使用手动发现和连接操作配置 NVMe/TCP。

[role="tabbed-block"]
====
.FC——Broadcom/Emulex
--
为Broadcom/Emulex适配器配置NVMe/FC。

. 确认您使用的是受支持的适配器型号：
+
.. 显示模型名称：
+
[source, cli]
----
cat /sys/class/scsi_host/host*/modelname
----
+
您应看到以下输出：

+
[listing]
----
LPe36002-M64
LPe36002-M64
----
.. 显示模型描述：
+
[source, cli]
----
cat /sys/class/scsi_host/host*/modeldesc
----
+
您应该会看到类似于以下示例的输出：

+
[listing]
----
Emulex LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
Emulex LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
----


. 确认您使用的是建议的Broadcom `lpfc` 固件和内置驱动程序：
+
.. 显示固件版本：
+
[source, cli]
----
cat /sys/class/scsi_host/host*/fwrev
----
+
以下示例显示固件版本：

+
[listing]
----
14.4.317.10, sli-4:6:d
14.4.317.10, sli-4:6:d
----
.. 显示收件箱驱动程序版本：
+
[source, cli]
----
cat /sys/module/lpfc/version
----
+
以下示例显示了驱动程序版本：

+
[listing]
----
0:14.2.0.13
----
+
有关支持的适配器驱动程序和固件版本的最新列表，请参见link:https://mysupport.netapp.com/matrix/["互操作性表工具"^]。



. 验证是否 `lpfc_enable_fc4_type`设置为"3"：
+
[source, cli]
----
cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
----
. 验证是否可以查看启动程序端口：
+
[source, cli]
----
cat /sys/class/fc_host/host*/<port_name>
----
+
以下示例显示端口标识：

+
[listing]
----
0x100000109bf0449c
0x100000109bf0449d
----
. 验证启动程序端口是否联机：
+
[source, cli]
----
cat /sys/class/fc_host/host*/port_state
----
+
您应看到以下输出：

+
[listing]
----
Online
Online
----
. 验证NVMe/FC启动程序端口是否已启用且目标端口是否可见：
+
[source, cli]
----
cat /sys/class/scsi_host/host*/nvme_info
----
+
.显示示例
[%collapsible]
=====
[listing, subs="+quotes"]
----
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109bf0449c WWNN x200000109bf0449c DID x061500 *ONLINE*
NVME RPORT       WWPN x200bd039eab31e9c WWNN x2005d039eab31e9c DID x020e06 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2006d039eab31e9c WWNN x2005d039eab31e9c DID x020a0a *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000002c Cmpl 000000002c Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000000008ffe8 Issue 000000000008ffb9 OutIO ffffffffffffffd1
        abort 0000000c noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 0000000c Err 0000000c
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109bf0449d WWNN x200000109bf0449d DID x062d00 *ONLINE*
NVME RPORT       WWPN x201fd039eab31e9c WWNN x2005d039eab31e9c DID x02090a *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x200cd039eab31e9c WWNN x2005d039eab31e9c DID x020d06 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 0000000041 Cmpl 0000000041 Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 00000000000936bf Issue 000000000009369a OutIO ffffffffffffffdb
        abort 00000016 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000016 Err 00000016
----
=====


--
.FC——Marvell/QLogic
--
为Marvell/QLogic适配器配置NVMe/FC。

. 验证您是否正在运行受支持的适配器驱动程序和固件版本：
+
[source, cli]
----
cat /sys/class/fc_host/host*/symbolic_name
----
+
以下示例显示了驱动程序和固件版本：

+
[listing]
----
QLE2772 FW:v9.15.00 DVR:v10.02.09.100-k
QLE2772 FW:v9.15.00 DVR:v10.02.09.100-k
----
. 请验证 `ql2xnvmeenable` 已设置。这样、Marvell适配器便可用作NVMe/FC启动程序：
+
[source, cli]
----
cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
----
+
预期输出为1。



--
.TCP
--
NVMe/TCP 协议不支持自动连接操作。相反，您可以通过执行 NVMe/TCP 来发现 NVMe/TCP 子系统和命名空间 `connect`或者 `connect-all`手动操作。

. 验证启动程序端口是否可以通过受支持的NVMe/TCP LIF提取发现日志页面数据：
+
[source, cli]
----
nvme discover -t tcp -w <host-traddr> -a <traddr>
----
+
.显示示例
[%collapsible]
=====
[listing, subs="+quotes"]
----
nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.24 Discovery Log Number of Records 20, Generation counter 45
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  6
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.6.25
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  1
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.5.24
sectype: none
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  4
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.6.24
sectype: none
=====Discovery Log Entry 3======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  2
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.5.25
sectype: none
=====Discovery Log Entry 4======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  6
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
traddr:  192.168.6.25
sectype: none
=====Discovery Log Entry 5======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  1
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
..........
----
=====
. 验证所有其他NVMe/TCP启动程序-目标LIF组合是否可以成功提取发现日志页面数据：
+
[source, cli]
----
nvme discover -t tcp -w <host-traddr> -a <traddr>
----
+
.显示示例
[%collapsible]
=====
[listing, subs="+quotes"]
----
nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.24
nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.25
nvme discover -t tcp -w 192.168.5.1 -a 192.168.5.24
nvme discover -t tcp -w 192.168.5.1 -a 192.168.5.25
----
=====
. 运行 `nvme connect-all` 在节点中所有受支持的NVMe/TCP启动程序-目标SIP上运行命令：
+
[source, cli]
----
nvme connect-all -t tcp -w host-traddr -a traddr -l <ctrl_loss_timeout_in_seconds>
----
+
.显示示例
[%collapsible]
=====
[listing, subs="+quotes"]
----
nvme	connect-all	-t	tcp	-w	192.168.5.1	-a	192.168.5.24	-l -1
nvme	connect-all	-t	tcp	-w	192.168.5.1	-a	192.168.5.25	-l -1
nvme	connect-all	-t	tcp	-w	192.168.6.1	-a	192.168.6.24	-l -1
nvme	connect-all	-t	tcp	-w	192.168.6.1	-a	192.168.6.25	-l -1
----
=====


[NOTE]
====
NetApp建议设置 `ctrl-loss-tmo option`到 `-1`这样，当路径丢失时，NVMe/TCP 发起程序会无限期地尝试重新连接。

====
--
====


== 步骤 3：可选，启用 NVMe/FC 的 1MB I/O。

ONTAP在识别控制器数据中报告最大数据传输大小 (MDTS) 为 8。这意味着最大 I/O 请求大小可达 1MB。要向 Broadcom NVMe/FC 主机发出 1MB 大小的 I/O 请求，您应该增加 `lpfc`的价值 `lpfc_sg_seg_cnt`参数从默认值 64 更改为 256。


NOTE: 这些步骤不适用于逻辑NVMe/FC主机。

.步骤
. 将 `lpfc_sg_seg_cnt`参数设置为256：
+
[source, cli]
----
cat /etc/modprobe.d/lpfc.conf
----
+
您应该会看到类似于以下示例的输出：

+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. 运行 `dracut -f`命令并重新启动主机。
. 验证的值是否 `lpfc_sg_seg_cnt`为256：
+
[source, cli]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----




== 步骤 4：验证多路径配置

验证内核NVMe多路径状态、ANA状态和ONTAP命名空间是否适用于NVMe-oF配置。

.步骤
. 验证是否已启用内核NVMe多路径：
+
[source, cli]
----
cat /sys/module/nvme_core/parameters/multipath
----
+
您应看到以下输出：

+
[listing]
----
Y
----
. 验证相应ONTAP命名库的适当NVMe-oF设置(例如、型号设置为NetApp ONTAP控制器、负载平衡iopolicy设置为循环)是否正确反映在主机上：
+
.. 显示子系统：
+
[source, cli]
----
cat /sys/class/nvme-subsystem/nvme-subsys*/model
----
+
您应看到以下输出：

+
[listing]
----
NetApp ONTAP Controller
NetApp ONTAP Controller
----
.. 显示策略：
+
[source, cli]
----
cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
----
+
您应看到以下输出：

+
[listing]
----
round-robin
round-robin
----


. 验证是否已在主机上创建并正确发现命名空间：
+
[source, cli]
----
nvme list
----
+
.显示示例
[%collapsible]
====
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme0n1 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller
/dev/nvme0n2 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller
/dev/nvme0n3 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller

Namespace Usage   Format               FW            Rev
-----------------------------------------------------------
1                 85.90 GB / 85.90 GB  4 KiB + 0 B   FFFFFFFF
2                 85.90 GB / 85.90 GB  24 KiB + 0 B  FFFFFFFF
3	                85.90 GB / 85.90 GB  4 KiB + 0 B   FFFFFFFF

----
====
. 验证每个路径的控制器状态是否为活动状态且是否具有正确的ANA状态：
+
[source, cli]
----
nvme list-subsys /dev/nvme0n1
----
+
.展示 NVMe/FC 示例
[%collapsible]
====
[listing, subs="+quotes"]
----
nvme-subsys0 - NQN=nqn.1992- 08.com.netapp: 4b4d82566aab11ef9ab8d039eab31e9d:subsystem.nvme\
+-  nvme1 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203ad039eab31e9c host_traddr=nn-0x200034800d756a89:pn-0x210034800d756a89 *live optimized*
+-  nvme2 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203cd039eab31e9c host_traddr=nn-0x200034800d756a88:pn-0x210034800d756a88 *live optimized*
+- nvme3 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203ed039eab31e9c host_traddr=nn-0x200034800d756a89:pn-0x210034800d756a89 *live non-optimized*
+-  nvme7 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x2039d039eab31e9c host_traddr=nn-0x200034800d756a88:pn-0x210034800d756a88 *live non-optimized*
----
====
+
.展示 NVMe/TCP 示例
[%collapsible]
====
[listing, subs="+quotes"]
----
nvme-subsys0 - NQN=nqn.1992- 08.com.netapp: sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
\
+- nvme1 *tcp* traddr=192.168.5.25 trsvcid=4420 host_traddr=192.168.5.1 src_addr=192.168.5.1 *live optimized*
+- nvme10 *tcp* traddr=192.168.6.24 trsvcid=4420 host_traddr=192.168.6.1 src_addr=192.168.6.1 *live optimized*
+- nvme2 *tcp* traddr=192.168.5.24 trsvcid=4420 host_traddr=192.168.5.1 src_addr=192.168.5.1 *live non-optimized*
+- nvme9 *tcp* traddr=192.168.6.25 trsvcid=4420 host_traddr=192.168.6.1 src_addr=192.168.6.1 *live non-optimized*
----
====
. 验证NetApp插件是否为每个ONTAP 命名空间设备显示正确的值：
+
[role="tabbed-block"]
====
.列
--
[source, cli]
----
nvme netapp ontapdevices -o column
----
.显示示例
[%collapsible]
=====
[listing, subs="+quotes"]
----
Device         Vserver                  Namespace Path                NSID UUID                                  Size
-------------- ------------------------ ----------------------------- ---- ------------------------------------- ---------
/dev/nvme0n1   vs_coexistence_QLE2772   /vol/fcnvme_1_1_0/fcnvme_ns   1    159f9f88-be00-4828-aef6-197d289d4bd9  10.74GB
/dev/nvme0n2   vs_coexistence_QLE2772   /vol/fcnvme_1_1_1/fcnvme_ns   2    2c1ef769-10c0-497d-86d7-e84811ed2df6  10.74GB
/dev/nvme0n3   vs_coexistence_QLE2772   /vol/fcnvme_1_1_2/fcnvme_ns   3    9b49bf1a-8a08-4fa8-baf0-6ec6332ad5a4  10.74GB
----
=====
--
.JSON
--
[source, cli]
----
nvme netapp ontapdevices -o json
----
.显示示例
[%collapsible]
=====
[listing, subs="+quotes"]
----
{
  "ONTAPdevices" : [
    {
      "Device" : "/dev/nvme0n1",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_0/fcnvme_ns",
      "NSID" : 1,
      "UUID" : "159f9f88-be00-4828-aef6-197d289d4bd9",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
    {
      "Device" : "/dev/nvme0n2",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_1/fcnvme_ns",
      "NSID" : 2,
      "UUID" : "2c1ef769-10c0-497d-86d7-e84811ed2df6",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
    {
      "Device" : "/dev/nvme0n4",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_3/fcnvme_ns",
      "NSID" : 4,
      "UUID" : "f3572189-2968-41bc-972a-9ee442dfaed7",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
----
=====
--
====




== 步骤 5：可选，启用 1MB I/O 大小

ONTAP在识别控制器数据中报告最大数据传输大小 (MDTS) 为 8。这意味着最大 I/O 请求大小可达 1MB。要向 Broadcom NVMe/FC 主机发出 1MB 大小的 I/O 请求，您应该增加 `lpfc`的价值 `lpfc_sg_seg_cnt`参数从默认值 64 更改为 256。


NOTE: 这些步骤不适用于逻辑NVMe/FC主机。

.步骤
. 将 `lpfc_sg_seg_cnt`参数设置为256：
+
[source, cli]
----
cat /etc/modprobe.d/lpfc.conf
----
+
您应该会看到类似于以下示例的输出：

+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. 运行 `dracut -f`命令并重新启动主机。
. 验证的值是否 `lpfc_sg_seg_cnt`为256：
+
[source, cli]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----




== 第6步：查看已知问题

这些是已知问题：

[cols="20,40,40"]
|===
| NetApp 错误 ID | 标题 | Description 


| link:https://mysupport.netapp.com/site/bugs-online/product/HOSTUTILITIES/BURT/1479047["1479047"^] | Oracle Linux 8.x NVMe-oF 主机创建重复的持久发现控制器 (PDC) | 在 NVMe-oF 主机上，您可以使用  `nvme discover -p` 命令创建 PDC。使用此命令时，每个发起方-目标组合只能创建一个 PDC。However, if you are running Oracle Linux 8.x with an NVMe-oF host, a duplicate PDC is created each time `nvme discover -p` is executed.这会导致主机和目标设备上资源的不必要消耗。 
|===