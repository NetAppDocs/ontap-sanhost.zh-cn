---
sidebar: sidebar 
permalink: nvme_rhel_93.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: 如何使用ONTAP为RHEL 9.3配置NVMe-oF主机 
---
= 适用于采用ONTAP的RHEL 9.3的NVMe-oF主机配置
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
具有非对称命名空间访问(AANA)的Red Hat Enterprise Linux (RHEL) 9.3支持基于网络结构的NVMe (NVMe-oF)、包括基于光纤通道的NVMe (NVMe/FC)和其他传输。在NVMe-oF环境中、ANA相当于iSCSI和FC环境中的ALUA多路径功能、并可通过内核NVMe多路径实施。

对于采用ONTAP的RHEL 9.3的NVMe-oF主机配置、可获得以下支持：

* 除了NVMe/FC之外、还支持基于TCP的NVMe (NVMe/TCP)。本机NVMe-CLI软件包中的NetApp插件可显示NVMe/FC和NVMe/TCP命名库的ONTAP详细信息。
* 在给定主机总线适配器(HBA)上的同一主机上使用NVMe和SCSI流量并无明确的dm-dpath设置、以防止声明NVMe命名空间。


有关支持的配置的其他详细信息、请参见 link:https://mysupport.netapp.com/matrix/["NetApp 互操作性表工具"^]。



== 功能

默认情况下、RHEL 9.3已为NVMe命名空间启用内核NVMe多路径；因此、无需显式设置。



== 已知限制

目前不支持使用NVMe-oF协议启动SAN。



== 验证软件版本

您可以使用以下操作步骤验证支持的最低RHEL 9.3软件版本。

.步骤
. 在服务器上安装RHEL 9.3。安装完成后、验证是否正在运行指定的RHEL 9.3内核：
+
[listing]
----
# uname -r
----
+
*示例输出：*

+
[listing]
----
5.14.0-362.8.1.el9_3.x86_64
----
. 安装 `NVMe-CLI` 软件包：
+
[listing]
----
# rpm -qa|grep nvme-cli
----
+
*示例输出：*

+
[listing]
----
nvme-cli-2.4-10.el9.x86_64
----
. 安装 `libnvme` 软件包：
+
[listing]
----
#rpm -qa|grep libnvme
----
+
*示例输出*

+
[listing]
----
libnvme-1.4-7.el9.x86_64
----
. 在RHEL 9.3主机上、检查中的hostnqn字符串 `/etc/nvme/hostnqn`：
+
[listing]
----
# cat /etc/nvme/hostnqn
----
+
*示例输出*

+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid:060fd513-83be-4c3e-aba1-52e169056dcf
----
. 验证是否已 `hostnqn` 字符串与匹配 `hostnqn` ONTAP 阵列上对应子系统的字符串：
+
[listing]
----
::> vserver nvme subsystem host show -vserver vs_nvme147
----
+
*示例输出：*

+
[listing]
----
Vserver     Subsystem          Host NQN
----------- --------------- ----------------------------------------------------------
vs_nvme147   rhel_147_LPe32002    nqn.2014-08.org.nvmexpress:uuid:060fd513-83be-4c3e-aba1-52e169056dcf
----
+

NOTE: 如果 `hostnqn` 字符串不匹配、请使用 `vserver modify` 用于更新的命令 `hostnqn` 要匹配的相应ONTAP 阵列子系统上的字符串 `hostnqn` 字符串自 `/etc/nvme/hostnqn` 在主机上。





== 配置 NVMe/FC

您可以为Broadcom/Emulex或Marvell/Qlogic适配器配置NVMe/FC。

[role="tabbed-block"]
====
.Broadcom/Emulex
--
.步骤
. 验证您使用的适配器型号是否受支持：
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
----
+
*示例输出：*

+
[listing]
----
LPe32002-M2
LPe32002-M2
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
----
+
*示例输出：*

+
[listing]
----
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. 确认您使用的是建议的Broadcom `lpfc` 固件和内置驱动程序：
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
14.2.539.16, sli-4:2:c
14.2.539.16, sli-4:2:c

# cat /sys/module/lpfc/version
0:14.2.0.12
----
+
有关支持的适配器驱动程序和固件版本的最新列表、请参见 link:https://mysupport.netapp.com/matrix/["NetApp 互操作性表工具"^]。

. 请验证 `lpfc_enable_fc4_type` 设置为 `3`：
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. 验证启动程序端口是否已启动且正在运行、以及您是否可以看到目标生命周期：
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b3c081f
0x100000109b3c0820

----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
+
[listing, subs="+quotes"]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109b3c081f WWNN x200000109b3c081f DID x062300 *ONLINE*
NVME RPORT       WWPN x2143d039ea165877 WWNN x2142d039ea165877 DID x061b15 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2145d039ea165877 WWNN x2142d039ea165877 DID x061115 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000040b Cmpl 000000040b Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000001f5c4538 Issue 000000001f58da22 OutIO fffffffffffc94ea
abort 00000630 noxri 00000000 nondlp 00001071 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000630 Err 0001bd4a
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109b3c0820 WWNN x200000109b3c0820 DID x062c00 *ONLINE*
NVME RPORT       WWPN x2144d039ea165877 WWNN x2142d039ea165877 DID x060215 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2146d039ea165877 WWNN x2142d039ea165877 DID x061815 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000040b Cmpl 000000040b Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000001f5c3618 Issue 000000001f5967a4 OutIO fffffffffffd318c
abort 00000629 noxri 00000000 nondlp 0000044e qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000629 Err 0001bd3d

----


--
.适用于NVMe/FC的Marvell/QLogic FC适配器
--
RHEL 9.3 GA内核中附带的本机内置qla2xxx驱动程序已进行了最新修复。这些修复程序对于ONTAP支持至关重要。

.步骤
. 验证您是否正在运行受支持的适配器驱动程序和固件版本：
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
----
+
*示例输出*

+
[listing]
----
QLE2772 FW:v9.10.11 DVR:v10.02.08.200-k
QLE2772 FW:v9.10.11 DVR:v10.02.08.200-k
----
. 请验证 `ql2xnvmeenable` 已设置。这样、Marvell适配器便可用作NVMe/FC启动程序：
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----


--
====


=== 启用1 MB I/O (可选)

ONTAP会在"识别 控制器"数据中报告MDTS (MAX Data传输大小)为8。这意味着最大I/O请求大小最多可以为1 MB。要向Broadcom NVMe/FC主机发出大小为1 MB的I/O请求、必须将 `lpfc` `lpfc_sg_seg_cnt`参数的值从默认值64增加到256。


NOTE: 以下步骤不适用于逻辑NVMe/FC主机。

.步骤
. 将 `lpfc_sg_seg_cnt`参数设置为256：
+
[listing]
----
cat /etc/modprobe.d/lpfc.conf
----
+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. 运行 `dracut -f`命令并重新启动主机：
. 验证是否 `lpfc_sg_seg_cnt`为256：
+
[listing]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----
+
预期值为256。





== 配置 NVMe/TCP

NVMe/TCP没有自动连接功能。因此、如果某个路径发生故障、并且未在默认超时时间10分钟内恢复、则NVMe/TCP无法自动重新连接。为了防止超时、您应将故障转移事件的重试期限至少设置为30分钟。

.步骤
. 验证启动程序端口是否可以通过受支持的NVMe/TCP LIF提取发现日志页面数据：
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*示例输出：*

+
[listing, subs="+quotes"]
----
# nvme discover -t tcp -w 192.168.167.1 -a 192.168.167.16

Discovery Log Number of Records 8, Generation counter 10
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: *current discovery subsystem*
treq:    not specified
portid:  0
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.bbfb4ee8dfb611edbd07d039ea165590:discovery
traddr:  192.168.166.17
eflags:  *explicit discovery connections, duplicate discovery information*
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: *current discovery subsystem*
treq:    not specified
portid:  1
trsvcid: 8009
subnqn:  nqn.1992 08.com.netapp:sn.bbfb4ee8dfb611edbd07d039ea165590:discovery
traddr:  192.168.167.17
eflags:  *explicit discovery connections, duplicate discovery information*
sectype: none
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: *current discovery subsystem*
treq:    not specified
portid:  2
trsvcid: 8009
subnqn:  nqn.1992-
08.com.netapp:sn.bbfb4ee8dfb611edbd07d039ea165590:discovery
traddr:  192.168.166.16
eflags: *explicit discovery connections, duplicate discovery information*
sectype: none
=====Discovery Log Entry 3======
trtype:  tcp
adrfam:  ipv4
subtype: *current discovery subsystem*
treq:    not specified
portid:  3
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.bbfb4ee8dfb611edbd07d039ea165590:discovery
traddr:  192.168.167.16
eflags:  *explicit discovery connections, duplicate discovery information*
sectype: none
...

----
. 验证其他NVMe/TCP启动程序-目标LIF组合是否能够成功提取发现日志页面数据：
+
[listing]
----
nvme discover -t tcp -w host-traddr -a traddr
----
+
*示例输出：*

+
[listing]
----
#nvme discover -t tcp -w 192.168.166.5 -a 192.168.166.22
#nvme discover -t tcp -w 192.168.166.5 -a 192.168.166.23
#nvme discover -t tcp -w 192.168.167.5 -a 192.168.167.22
#nvme discover -t tcp -w 192.168.167.5 -a 192.168.167.23
----
. 运行 `nvme connect-all` 命令、并将控制器丢失超时期限至少设置为30分钟或1800秒：
+
[listing]
----
nvme connect-all -t tcp -w host-traddr -a traddr -l 1800
----
+
*示例输出：*

+
[listing]
----
#	nvme	connect-all	-t	tcp	-w	192.168.166.1	-a	192.168.166.16 -l	1800
#	nvme	connect-all	-t	tcp	-w	192.168.166.1	-a	192.168.166.17 -l	1800
#	nvme	connect-all	-t	tcp	-w	192.168.167.1	-a	192.168.167.16 -l	1800
#	nvme	connect-all	-t	tcp	-w	192.168.167.1	-a	192.168.167.17 -l	1800
----




== 验证 NVMe-oF

您可以使用以下操作步骤验证NVMe-oF。

.步骤
. 验证是否已启用内核NVMe多路径：
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. 验证相应ONTAP命名库的适当NVMe-oF设置(例如、型号设置为NetApp ONTAP控制器、负载平衡iopolicy设置为循环)是否正确反映在主机上：
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller
----
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. 验证是否已在主机上创建并正确发现命名空间：
+
[listing]
----
# nvme list
----
+
*示例输出：*

+
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme5n21 81CYrNQlis3WAAAAAAAB	NetApp ONTAP Controller


Namespace Usage    Format             FW             Rev
-----------------------------------------------------------
1                 21.47 GB / 21.47 GB	4 KiB + 0 B   FFFFFFFF
----
. 验证每个路径的控制器状态是否为活动状态且是否具有正确的ANA状态：
+
[role="tabbed-block"]
====
.NVMe/FC
--
[listing]
----
# nvme list-subsys /dev/nvme5n21
----
*示例输出：*

[listing, subs="+quotes"]
----
nvme-subsys4 - NQN=nqn.1992-08.com.netapp:sn.e80cc121ca6911ed8cbdd039ea165590:subsystem.rhel_
147_LPE32002
\
 +- nvme2 *fc* traddr=nn-0x2142d039ea165877:pn-0x2144d039ea165877,host_traddr=nn-0x200000109b3c0820:pn-0x100000109b3c0820 *live optimized*
 +- nvme3 *fc* traddr=nn-0x2142d039ea165877:pn-0x2145d039ea165877,host_traddr=nn-0x200000109b3c081f:pn-0x100000109b3c081f *live non-optimized*
 +- nvme4 *fc* traddr=nn-0x2142d039ea165877:pn-0x2146d039ea165877,host_traddr=nn-0x200000109b3c0820:pn-0x100000109b3c0820 *live non-optimized*
 +- nvme6 *fc* traddr=nn-0x2142d039ea165877:pn-0x2143d039ea165877,host_traddr=nn-0x200000109b3c081f:pn-0x100000109b3c081f *live optimized*
----
--
.NVMe/TCP
--
[listing]
----
# nvme list-subsys /dev/nvme1n1
----
*示例输出：*

[listing, subs="+quotes"]
----

nvme-subsys1 - NQN=nqn.1992- 08.com.netapp:sn. bbfb4ee8dfb611edbd07d039ea165590:subsystem.rhel_tcp_95
+- nvme1 *tcp* traddr=192.168.167.16,trsvcid=4420,host_traddr=192.168.167.1,src_addr=192.168.167.1 *live*
+- nvme2 *tcp* traddr=192.168.167.17,trsvcid=4420,host_traddr=192.168.167.1,src_addr=192.168.167.1 *live*
+- nvme3 *tcp* traddr=192.168.167.17,trsvcid=4420,host_traddr=192.168.166.1,src_addr=192.168.166.1 *live*
+- nvme4 *tcp* traddr=192.168.166.16,trsvcid=4420,host_traddr=192.168.166.1,src_addr=192.168.166.1 *live*


----
--
====
. 验证NetApp插件是否为每个ONTAP 命名空间设备显示正确的值：
+
[role="tabbed-block"]
====
.列
--
[listing]
----
# nvme netapp ontapdevices -o column
----
*示例输出：*

[listing]
----
Device        Vserver   Namespace Path
----------------------- ------------------------------
/dev/nvme0n1 vs_tcp           /vol/vol1/ns1



NSID       UUID                                   Size
------------------------------------------------------------
1          6fcb8ea0-dc1e-4933-b798-8a62a626cb7f	21.47GB
----
--
.JSON
--
[listing]
----
# nvme netapp ontapdevices -o json
----
*示例输出*

[listing]
----
{

"ONTAPdevices" : [
{

"Device" : "/dev/nvme1n1",
"Vserver" : "vs_tcp_95",
"Namespace_Path" : "/vol/vol1/ns1",
"NSID" : 1,
"UUID" : "6fcb8ea0-dc1e-4933-b798-8a62a626cb7f",
"Size" : "21.47GB",
"LBA_Data_Size" : 4096,
"Namespace_Size" : 5242880
},

]
}

----
--
====




== 已知问题

对于采用ONTAP版本的RHEL 9.3、NVMe-oF主机配置没有已知问题。
